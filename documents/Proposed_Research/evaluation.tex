\section{Evaluation}

We propose to evaluate our tool on a series of Java programs from the DARPA STAC program as well as a set of classic side channel vulnerabilites, such as CRIME \cite{crime} and simple string comparison. The DARPA STAC programs are sizeable, containing thousands of methods. Side channel vulnerabilities are either in timing or space, such as the sizes of encrypted packets. We plan to evaluate our method based on its ability to correctly locate side channel vulnerabilities in each of these programs. Our method will be considered successful if it is able to identify the branch conditions responsible for a side channel that leaks information about the provided secret value. Since our method is designed to be an over-approximation, we also plan to evaluate how useful predicate abstraction and symbolic execution are at reducing the number of false positives. 

%Since our method depends on a user defined threshold for the imbalance between paths, our test suite will also provide an means to evaluate the importance of this threshold. We plan to use this test suite to determine suitable values for both timing and space side channels. In the case of timing side channels, the threshold should be high enough so that the difference in time is observable even across a network. If the side channels in space are deterministic, then it may be the case that a threshold of zero is appropriate. \todo{probably to remove for space}