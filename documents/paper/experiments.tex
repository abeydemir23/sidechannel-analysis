\section{Experiments}

Our analysis was driven through experimentation with various programs containing side-channels of differing strengths. We will briefly describe our experimental setup, highlight some of our most interesting findings, and describe our contribution to the area of side channel detection. The tools we created for this
project are currently in development and open-sourced. 


\subsection{Setup}

All of our experiments have been run on the Java Virtual Machine (Java HotSpot 
64-bit Server), on a 7th generation Intel Core i7 at 3.8GHz with 4 cores and 32GB of RAM.

To showcase side-channels, we select to focus on timing side-channels, as they are common
and easily observable by direct measurement. As we're measuring time on a method-call level, 
we created a driver which, using \texttt{System.nanoTime()}, measures various method lengths,
via calling a single interface method, which many implementations of our examples override. 

We demonstrate our results using several versions of a single program, \texttt{PasswordChecker}
which is a well-known example of timing side-channels. All source code is provided in the appendix.

\texttt{PasswordChecker.checkPassword(input)} is a method with simple semantics: given a public 
\texttt{input}, if a \texttt{secret} value exists, not present in any direct input-output flow, the 
method returns whether \texttt{input} is, character for character, equal to \texttt{secret}.

Different implementations of \texttt{PasswordChecker} have different behaviours. For example,
the na\"ive implementation that would be built for speed, includes early returns as soon as
it is clear that either the lengths of the two strings are different, or that a character
mismatch has happened. If we try to represent the time needed by the method
to finish, we can write it as $T = t_{len} + n\cdot t_{match} + \epsilon$, where $t_{len}$ is the time needed for
checking the lengths of the two strings, $t_{match}$ is the time needed to match two characters, and $\epsilon$ is the noise in the measurement. We consider that $\epsilon \ll \texttt{min}(t_{len}, t_{match})$, or that the information lost as a result of $\epsilon$ being present is recoverable through taking multiple samples.

We notice that all the results of our measurements of $T$ can be put into at most $l$ equivalence classes, where $l = \texttt{length}(\texttt{secret})$. Knowing this, we can engineer a side-channel
attack where we can generate the \texttt{secret} by first ascertaining its length and then learning each character in turn. Once the length is known, the first character can be learnt by iterating over all possible values for that character and observing when we access a higher equivalence class (i.e. the program takes longer to execute). The process can be repeated for subsequent characters until the full \texttt{secret} has been leaked.

\texttt{PasswordChecker} can also be implemented in constant time using the XOR operator. This implementation choice removes the side channel resulting from the optimization previously discussed. Figures illustrating both the side channel in the na\"ive implementation as well as its disappearance are provided in the appendix. To accurately analyze timing information, we ran each version of \texttt{PasswordChecker} a million times. Choices for both the secret and the user's guess were drawn at random from a dictionary. To isolate the timing side channel, the length of the two strings are not compared. Instead we ensure that both are of at least length four and compare the first four characters element-wise. These simplifications allow the side channel to be more easily demonstratable but do not fundamental change its character. To ensure reliable timing information, we allow for a burn-in period of 100,000 samples before considering the information reliable. Experimentally, this seems to be far more than enough time to allow any compiler optimizations to occur. When analyzing our data, we use a simple outlier detection method based on the average and standard deviation to remove suspect data.   


%By rewriting this, we can decrease the information leak, at the cost of speed. Our main interest is in
%exploring ways in which a runtime system can be better or worse for exploiting side-channels, be it by
%ways of special bytecode, in which side-channel noise is greater by default, special language constraints
%or constructs, that make programmer-created side-channels harder to make, or side-channel specific optimizations or mechanisms.


\subsection{Methods of side-channel detection}

The presence or absence of certain types of side channels can be found by 
statically analyzing the structure of the program in question. For example, the vulnerability in na\"ive \texttt{PasswordChecker} is characterized by the shape of its control flow where obvious length
differences can be observed if we unroll the loop and count how many instructions there are in the resultant
paths. This inspired us to develop a tool to analyze the costs of possible paths through a control flow graph. 

As a first step, we searched for a tool to extract control flow graphs which had several properties we found important: $i$) functional minimality, $ii$) no dependency overhead, and $iii$) modularity and elasticity. Having found no tools that satisfy all three of these, we decided to build our own\footnote{Conflow, \href{https://goo.gl/FnomgF}{https://goo.gl/FnomgF}}, which enabled us to extract control-flow graphs at different levels of abstraction. It is written as a server-client tool, in the hopes of accumulating control-flow data in more than one research field and project; its development will be continued.

Using this tool, we extract the control flow graph of a method. We then define a cost model that acts as a static approximation of our observable value. As we are concerned with timing side-channels, we decided to use the number of bytecode instructions as our cost model and we extracted this information for each basic block in our control flow graph. Given this cost model, each node and back edge of the control flow graph can be annotated with a symbolic expression that provides an over-approximation of all possible cost values that could occur at that node. Boolean variables are introduced for each branch of the program and integer variables for each loop. This allows us to express the possible time spent in a branch, loop, or method symbolically in terms of those variables. 

Possible costs, at this point, can be compared using an off-the-shelf SMT-solver\footnote{$Z3$, for example}, basically solving for any valuation of the variables present that would make the difference in the costs of paths larger than some $\delta$. Using taint analysis, it is possible to determine which branch conditions can be influenced by confidential information. This would allow us to refine our analysis by requiring that the two paths differ only on branch conditions impacted by secret information. 

This static method can inform us of any shape-dictated side-channels occurring in the program, however it is weakened by any form of code transformations, be it the JIT, optimizations or, in scripting languages, obfuscation. Our full implementation of this path-cost analysis is still ongoing, but we have made good progress towards a completed tool. 



\subsection{Runtime options and their effect on side-channel strength}
To explore how the runtime options impact runtime, we implemented another variant of \texttt{PasswordChecker}. In this version, we introduce two flags initialized to true. All characters are compared. Whenever they don't match the first flag is set to false; whenever they do, the second one is. We analyzed the resulting bytecode in order to ensure that the number of bytecode instructions in both branches was identical. 

Because of this balance, our shape-based anaysis previously described would consider the program safe. However, running the same experiment on this variant of \texttt{PasswordChecker} resulted in a clear side channel! The figure is again given in the appendix. We were not immediately sure of the reason for this, so we decided to disable JIT and re-experiment in the hopes of gaining more insight. In this case, not only did each run take almost two orders of magnitude longer, but the side chanenl dissapeared!

We hypothesized that this side-channel might be due to the more frequent execution of the branch taken when two characters are not equal compared to the branch taken when they are. This imabalance in frequency means an optimization introduced by branch prediction could be responsible. We were unable to turn off branch prediction but we did run another experiment to help understand this behavior. This time we modified the distribution of guesses for the password so that the first character was guessed correctly approximately 50 percent of the time. When we ran these experiments with JIT-enabled, there was no longer a side channel. We believe that this confirms our hypothesis that the reason for the side channel is branch prediction based on how much more frequent one branch is. Another unexpected consequence is that the user's interaction with the system can impact the presence and strengths of side channels. One distribution of guesses resulted in compiler optimizations that introduced a vulnerability while another did not. We have not yet been able to fully explore this dimension of side-channel analysis but to our knowledge it has not yet been explored in the literature and we believe it could lead to new exploits. 

\subsubsection{Inlining experiment} We decided to experiment with additional compiler options in order to determine their potential impact on side channels. One of these was inlining, which can be disabled using Java Hotspot VM options. We wrote a very simple program in which the same function is called along two different paths, one of which is taken much more frequently than the other. We hypothesized that inlining along the more common path might occur, resulting in a side channel that allows us to tell which path was taken. Experimentally, this was indeed the case with the average time of the more frequent path being 25-30 nanoseconds and that of the less frequent being over 20000 nanoseconds. When we disabled inlining, this side channel dissapeared. 